## PATTERN: CONTAINERIZE APPLICATIONS ## 

### Rationale
Containers have rapidly increased in popularity by making it easy to develop, promote and deploy code consistently across different environments. Containers are an abstraction at the application layer, wrapping up your code with necessary libraries, dependencies, and environment settings into a single executable package. Containers are intended to simplify the deployment of code, but managing thousands of them is no simple task. When it comes to creating highly available deployments, scaling up and down according to load, checking container health and replacing unhealthy containers with new ones, exposing ports and load balancing – another tool is needed. This is where container orchestration comes in. Container orchestration platforms are a suitable alternative when you are constrained by the limitations of FaaS. Use Container orchestrators when you:
*	Do not want vendor lock-in?
*	Want to develop stateful services that need to aware of each other in a cluster?
*	Have complex business logic i.e. have higher memory, disk and time requirements?
*	Want to develop services using a variety of languages and frameworks ?
*	Cannot tolerate function initialization times or cold starts?
*	Need to deeply monitor the behavior of each service instance?
* Containers are also very useful in migrating monolithic legacy applications to the cloud.?

The above considerations do not necessarily make the choice a binary one. Serverless and containers have strengths that can complement the other’s weaknesses, and incorporating these two technologies together can be highly beneficial. You can build a large, complex application with a container-based microservices architecture. But the application can hand off some back-end tasks, such as data transfer, file backups, and alert triggering, to serverless functions. This would save money and could increase the application’s performance.

### Solution
k8s is the accepted winner in this space after much competition with Mesos and Docker swarm. Even so, the platform decision can still be considered open due to the proprietary offerings provided by every cloud vendor even though they have been quick in providing managed k8s alternatives. The criteria for selection can be as follows:
*	**Ease of deployment** – Use proprietary offerings such as AWS ECS or Fargate. Opt for this option when speed is the most important criteria. The obvious advantage is you are free from managing your own cluster and that it seamless integrates with rest of the cloud vendor services. Even though ECS is a proprietary AWS solution, a viable alternative is to use Fargate compute engine with ECS to avoid vendor specific platforms. At its core, Fargate is a container service (with serverless attributes), so portability isn’t a concern. Fargate also works with k8s via EKS and thus is very portable to other cloud platforms such as Azure AKS or Google Cloud Platform (Google k8s Engine).
*	**Hedged your bets on k8s** – Use managed k8s (AWS EKS or Azure AKS or GCP GKE). Due to the complexity involved in designing and operating k8s clusters, it is generally advisable to leverage managed services provided by your cloud vendor.
*	**Need full control & autonomy** – Run containers on vendor provided compute such as AWS EC2, GCP GCE or Azure VMs. The challenge with this option is that since you do not use an orchestration platform, you depend upon VM-level features such as auto-scaling, auto-healing, rolling updates and load balancing. 

One of the early questions to answer is how to implement cross-cutting concerns such as service discovery, service-to-service and origin-to-service security, observability (including telemetry and distributed tracing), rolling releases and resiliency. This is implemented using a class of technologies called as Service mesh. Service mesh is an approach to operating a secure, fast and reliable microservices ecosystem. It has been an important stepping stone in making it easier to adopt microservices at scale. It offers discovery, security, tracing, monitoring and failure handling. Examples of service mesh platforms in open source are Istio and linkerd. In native offerings, AWS has released App Mesh service in public preview, Azure provides the Azure Fabric Mesh service in its proprietary micro services framework called Service Fabric and GCP provides integration between k8s and Istio.

[Next - PATTERN: OUTSOURCE SECURITY OF MICRO SERVICES](https://github.com/srikanthkotekar/ideasworthsharing/blob/master/Building-Modern-Cloud-Native-Apps/5.5%20PATTERN:%20OUTSOURCE%20SECURITY%20OF%20MICRO%20SERVICES.md)
